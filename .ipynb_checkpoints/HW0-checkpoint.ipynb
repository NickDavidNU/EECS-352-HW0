{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 0 — (5 points)\n",
    "======\n",
    "## Overview\n",
    "The goal of this assignment is to set up your development environment and to familiarize you with some of the Python packages you will be using this quarter. We will be using Jupyter notebooks (previously known as IPython notebooks) for homeworks this quarter. The homeworks will be distributed as notebooks and you will submit them as notebooks—in fact, what you are reading now is a Jupyter notebook.\n",
    "\n",
    "### What to hand in\n",
    "You are to submit the following things for this homework:\n",
    "1. A Jupyter notebook containing all code and output (figures and audio). I should be able to evaluate the file to reproduce all output. \n",
    "1. Any other data that we tell you to save to a file (e.g. audio files).\n",
    "\n",
    "NOTE: To make sure that when I reevaluate your code it generates the output you expect, it's good practice to restart the Jupyter Python kernel, clear all output, and then run all cells again. Since cells can be run in any order and deleted, etc., it's easy for you to accidentally break your code and not realize it... :/\n",
    "\n",
    "### How to hand it in\n",
    "To submit your lab:\n",
    "1. Compress all of the files specified into a .zip file. \n",
    "1. Name the file in the following manner, firstname_lastname_hw0.zip. For example, Bryan_Pardo_hw0.zip. \n",
    "1. Submit this .zip file via Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\" class=\"alert alert-danger\"><h3>CHECK CANVAS FOR DUE DATE</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>(.5 points): What is the class policy on late submissions for homeworks? Copy and paste it into the empty Markdown cell below.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homeworks are due by the due date on Canvas. Late assignments lose 50% of points per day late, rounded UP to the nearest day. That means if you are 1 minute late, you lose 1/2 of the points. If you are 1 day and 1 minute late, you lose all the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>(1.5 points):</b> This homework is a bit different than others since it's partially a tutorial. Simply reading through the assignment and generating the output for each cell accounts for 2 points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup your development environment\n",
    "### Install Miniconda\n",
    "Miniconda is a Python distribution that we will be using in the course. It is the little sibling of [Anaconda](https://www.continuum.io/downloads). Using Miniconda ensures that we are all using the same environment with the same version of packages.\n",
    "\n",
    "To install Miniconda, go to http://conda.pydata.org/miniconda.html, download the Python 2.7 Miniconda for your operating system. Then follow the ['quick install' instructions](http://conda.pydata.org/docs/install/quick.html).\n",
    "\n",
    "### Read the Conda documentation\n",
    "Conda is both the environment and package manager for Miniconda. For those familiar with Virtualenv and Pip, Conda performs both of their jobs. To learn about why you should use an environment manager and to get familiar with Conda, read through a quick tutorial [here](http://conda.pydata.org/docs/test-drive.html).\n",
    "\n",
    "### Create a Conda environment for the class\n",
    "Let's create a Conda environment that we will use for all of the homeworks. To create a Conda environment and install Python packages needed for the course, run the following command in the terminal:\n",
    "```\n",
    "conda create --name eecs352 ipython-notebook scipy numpy matplotlib scikit-learn\n",
    "```\n",
    "\n",
    "\n",
    "### Activate your Conda environment\n",
    "Before you use a Conda environment in a new terminal session, you must activate it with the following command:\n",
    "\n",
    "**Linux, OS X**: `source activate eecs352`\n",
    "\n",
    "**Windows**: `activate eecs352`\n",
    "\n",
    "\n",
    "### Install Librosa\n",
    "Librosa is an additional python package we will be using in the class for extracting features from audio files. However, this package is not hosted in the Anaconda.org repository, but it is in the PyPI repository. Packages in this repository can be installed using Pip. To install librosa run the following command while your `eecs352` environment is activated:\n",
    "```\n",
    "pip install librosa\n",
    "```\n",
    "\n",
    "### Additional Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Unless instructed in a future homework assignment, <b>DO NOT INSTALL OTHER PACKAGES INTO THE eecs352 CONDA ENVIRONMENT</b>. This constraint is in place so that you do not use a package that is not installed on our system. You will be graded on whether your code runs in our Conda environment with the specified installed packages (i.e. a condo environment created as detailed above). <b>IF YOUR CODE DOES NOT RUN IN OUR CONDA ENVIRONMENT, YOU WILL NOT GET CREDIT</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open the HW0 notebook\n",
    "This quarter, we're trying something new. Instead of submitting separate source code files, audio files, and response pdfs, you will simply submit a Jupyter notebook file that contains all of that data (with possibly a few extra files). In fact, the file you are reading right now is a Jupyter notebook. For every assignment, we will provide you with a Jupyter notebook which you will complete with your own code, figures, data, and responses. \n",
    "\n",
    "1. Open a terminal and navigate to the HW0 folder (i.e. the folder that contains the file you are reading)\n",
    "1. Activate your `eecs352` environment if you have not already done so\n",
    "1. Start the Jupyter server and load the HW0 notebook file (HW0.ipynb), i.e.: \n",
    "```\n",
    "jupyter notebook HW0.ipynb\n",
    "```\n",
    "\n",
    "The last command should have opened your web browser to the HW0 notebook. If not, open your browser, type in `localhost:8888` and navigate to and open the notebook file.\n",
    "\n",
    "I highly recommend committing your notebook to a Github repository and checking in changes as you progress. Github now supports rendering of Jupyter notebooks which makes looking at previous versions very simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Getting help\n",
    "All of the Python tools and packages we will be using this quarter have excellent documentation:\n",
    "* **Conda** (manager for Python environments and packages): http://conda.pydata.org/docs/\n",
    "* **IPython** (interactive Python shell): http://ipython.readthedocs.org/en/stable/\n",
    "* **Jupyter** (notebook server for iPython): https://jupyter.readthedocs.org/en/latest/\n",
    "* **NumPy / SciPy** (scientific computing package): http://docs.scipy.org/doc/\n",
    "* **Matplotlib** (plotting package): http://matplotlib.org\n",
    "* **Scikit-Learn** (machine learning package): http://scikit-learn.org/stable/documentation.html\n",
    "* **Librosa** (audio feature extraction package): http://librosa.github.io/librosa/\n",
    "\n",
    "Much of this documentation can be accessed directly from the Jupyter Help menu along with other useful links to documentation on Markdown, Python, Jupyter Notebook, etc. If you have never used Jupyter or IPython Notebook before, I highly recommend reviewing the *User Interface Tour*, *Keyboard Shortcuts*, and *Notebook Help* links from the Help menu before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Confirm your environment is setup properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>(1 point):</b> Confirm that your environment has been setup properly with the correct packages. To receive the point, your package versions must be at least as high as those specified in parentheses. To print out the version numbers of the installed packages, execute the following \"cell\" (<code>Shift-Enter</code> will run a cell and move on to the next one, <code>Ctrl-Enter</code> will run a cell and stay on the current one.):\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/ENTER/envs/eecs352/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython version:       5.1.0 (need at least 4.0.1)\n",
      "Numpy version:        1.11.2 (need at least 1.10.1)\n",
      "SciPy version:        0.18.1 (need at least 0.16.0)\n",
      "Matplotlib version:    1.5.3 (need at least 1.5.0)\n",
      "Scikit-Learn version: 0.18.1 (need at least 0.17)\n",
      "Librosa version:       0.4.3 (need at least 0.4.1)\n"
     ]
    }
   ],
   "source": [
    "import IPython, numpy as np, scipy as sp, matplotlib.pyplot as plt, matplotlib, sklearn, librosa\n",
    "%matplotlib inline\n",
    "# NOTE: librosa may take a while to import\n",
    "\n",
    "print \"IPython version:      %6.6s (need at least 4.0.1)\" % IPython.__version__\n",
    "print \"Numpy version:        %6.6s (need at least 1.10.1)\" % np.__version__\n",
    "print \"SciPy version:        %6.6s (need at least 0.16.0)\" % sp.__version__\n",
    "print \"Matplotlib version:   %6.6s (need at least 1.5.0)\" % matplotlib.__version__\n",
    "print \"Scikit-Learn version: %6.6s (need at least 0.17)\" % sklearn.__version__\n",
    "print \"Librosa version:      %6.6s (need at least 0.4.1)\" % librosa.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a recent Miniconda/Anaconda install and followed the above instructions correctly, then all of your package versions should be at least as high as those in the parentheses. If not, install the correct versions, restart your kernel, and run the cell again. If you are running a previously installed Miniconda/Anaconda, you may simply have to update the packages in your environment (e.g. run \"`conda update --all`\" in your `eecs352` environment).\n",
    "\n",
    "**NOTE: If `librosa` warns you that it cannot import `scikits.samplerate`, don't worry—it should still run fine.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with audio signals\n",
    "Now, that our environment is set up, let's try synthesizing a few simple audio files. Just step through and evaluate each cell by pressing (`Shift-Enter`). \n",
    "\n",
    "Let's first synthesis a 2 second sine wave at an 220 Hz (the A below middle C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq = 220. # the frequency\n",
    "length = 3. # length in seconds\n",
    "sr = 44100. # the sampling rate (we'll talk about what this is soon...)\n",
    "t = np.arange(0,length*sr)/sr\n",
    "x = np.sin(2*np.pi*freq*t)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(t,x) # plot it with matplotlib\n",
    "plt.ylabel('amplitude')\n",
    "plt.xlabel('time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like much since there are so many cycles. Let's look at just the first 1000 samples to get a better idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "plt.plot(t[:1000],x[:1000])\n",
    "plt.ylabel('amplitude')\n",
    "plt.xlabel('time (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we're going to be plotting a lot of audio files, let's write a function for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_audio(x, sr, figsize=(16,4)):\n",
    "    \"\"\"\n",
    "    A simple audio plotting function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.ndarray\n",
    "        Audio signal to plot\n",
    "    sr: int\n",
    "        Sample rate\n",
    "    figsize: tuple\n",
    "        A duple representing the figure size (xdim,ydim)\n",
    "    \"\"\"\n",
    "    length = float(x.shape[0]) / sr\n",
    "    t = np.linspace(0,length,x.shape[0])\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(t, x)\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_audio(x[:1000], sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh, that's better. \n",
    "\n",
    "Jupyter/IPython has an extension to embed audio files. Let's use it to listen to our signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, Jupyter notebooks will not save if they get to be over 100MB. Be careful with embedding too much audio in your notebooks! Let's spice it up a bit by adding a sine wave that is a 5th (7 semitones) lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq2 = freq * 2**(-7/12.) \n",
    "x2 = np.sin(2*np.pi*freq2*t)\n",
    "x3 = x + x2\n",
    "# normalize so that we don't exceed the range -1:+1 (which can cause the output to distort). \n",
    "# `Audio` does this for us though, so if you forget, it's not a big deal.\n",
    "x3 = x3 / np.max(np.abs(x3)) \n",
    "Audio(x3, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's modulate the amplitude with a low, sub-audio frequency (4 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mod_freq = 4\n",
    "mod_sig = (np.sin(2*mod_freq*np.pi*t) + 1.0) * 0.5\n",
    "x4 = x3 * mod_sig\n",
    "Audio(x4, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this waveform look like and what does the signal we modulated it with look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_audio(x4, sr)\n",
    "\n",
    "plot_audio(x4[:8000], sr)\n",
    "\n",
    "plot_audio(mod_sig, sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, huh?\n",
    "\n",
    "How about some distortion??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distort(x, gain=1.0):\n",
    "    \"\"\"\n",
    "    Cubic soft-clipping\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_sig : np.ndarray\n",
    "        The input signal\n",
    "    gain : float\n",
    "        The input gain. Increase this value to distort more.\n",
    "    \"\"\"\n",
    "    x = x * gain\n",
    "    x[(x >= -1) & (x <= 1)] = x[(x >= -1) & (x <= 1)] - (x[(x >= -1) & (x <= 1)]**3) / 3.0\n",
    "    x[x <= -1] = -2.0 / 3.0\n",
    "    x[x >= 1] = 2.0 / 3.0\n",
    "    \n",
    "    return x\n",
    "\n",
    "x5 = distort(x4, 2.0) # try different gain values to hear/see how the sound is affected. Feel free to crank it to 11.\n",
    "plot_audio(x5, sr)\n",
    "Audio(x5, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading an audio file\n",
    "First, let's read in an audio file, a recording of Satie's *Gymnopédie No.1*. We can use librosa for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "satie, sr = librosa.load('satie.wav', sr=sr, duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`librosa.load` outputs two variables, the signal(`satie`) and the sample rate (`sr`). What did the inputs `sr` and `duration` do? Run `%pdoc <function>` to see the docstring of a function, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pdoc librosa.load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: The default behavior of `librosa.load` is to resample the audio signal to a sample rate of 22050. To override this behavior, you must supply the `sr` argument, setting it to your desired sample rate (44100 in our case). If you do not do this, you may have unexpected results such as causing the audio signal to be pitched up or pitched down.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot and listen to the signal we just read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_audio(satie, sr)\n",
    "Audio(satie, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... Satie is missing something... more cowbell? Let's load in a cowbell file and put a cowbell on every beat (quarter notes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cowbell, sr = librosa.load('cowbell.wav', sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x` is the signal, and `sr` is the sampling rate. Let's plot and listen to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_audio(cowbell, sr)\n",
    "Audio(cowbell, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale the amplitude down down a bit since it's a little loud in comparison to the Satie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cowbell = cowbell * 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The internet told me that this performance was played at 76 beats per minute (BPM). I wrote a file that has the onset times at 76 BPM. Let's read it in. Reading and writing files is really easy in python—read more about it [here](https://docs.python.org/2/tutorial/inputoutput.html#reading-and-writing-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('76bpm.txt','rb') as f:\n",
    "    beats = [int(l) for l in f.readlines()]\n",
    "print beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add a cowbell at each of these times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "satie_w_cowbell = satie.copy()\n",
    "for start in beats:\n",
    "    stop = start + cowbell.shape[0]\n",
    "    satie_w_cowbell[start:stop] += cowbell\n",
    "\n",
    "plot_audio(satie_w_cowbell, sr)\n",
    "Audio(satie_w_cowbell, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing audio files\n",
    "\n",
    "Here is a function for writing wave files (we'll include this at the top of homework in which it is needed). Let's write our new cowbell infused Satie to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "\n",
    "def wavwrite(filepath, data, sr, norm=True, dtype='int16',):\n",
    "    '''\n",
    "    Write wave file using scipy.io.wavefile.write, converting from a float (-1.0 : 1.0) numpy array to an integer array\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The path of the output .wav file\n",
    "    data : np.array\n",
    "        The float-type audio array\n",
    "    sr : int\n",
    "        The sampling rate\n",
    "    norm : bool\n",
    "        If True, normalize the audio to -1.0 to 1.0 before converting integer\n",
    "    dtype : str\n",
    "        The output type. Typically leave this at the default of 'int16'.\n",
    "    '''\n",
    "    if norm:\n",
    "        data /= np.max(np.abs(data))\n",
    "    data = data * np.iinfo(dtype).max\n",
    "    data = data.astype(dtype)\n",
    "    scipy.io.wavfile.write(filepath, sr, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The `norm` parameter to the function, normalizes the signal to -1 to +1 also so you don't have to worry about it. \n",
    "# By default this parameter is set to True\n",
    "wavwrite('satie_w_cowbell.wav', satie_w_cowbell, sr, norm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm... 76 BPM sounded a bit off, didn't it?? We can also tell that it is off by looking at the plot above—the sharp spikes in amplitude (which are the cowbell) are not aligned with the other (less sharp, and longer decaying) spikes (the piano). We want all of the spikes to be aligned with each other. Let's try using `librosa` to detect the onsets instead of using the times from the file!\n",
    "\n",
    "Librosa has a lot of great functions for analyzing audio. One of which is [`librosa.onset.onset_detect`](https://librosa.github.io/librosa/generated/librosa.onset.onset_detect.html#librosa.onset.onset_detect) for detecting onsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The hop length of the onset detector in samples (we'll talk about this more later when we \n",
    "# talk about the spectral analysis and the STFT). Decreasing this number increases the resolution of the detector.\n",
    "hop = 128\n",
    "\n",
    "# Detect onsets. The `wait` parameter specifies how many frames (i.e. hop lengths) we should wait \n",
    "# before detecting another onset. This allows us to filter out spurious onsets.\n",
    "onset_frames = librosa.onset.onset_detect(satie, sr, hop_length=hop, wait=((0.5 * sr) / hop))\n",
    "\n",
    "# The onset detector outputs frames. We need to convert this to samples.\n",
    "onsets = librosa.frames_to_samples(onset_frames, hop_length=hop)\n",
    "\n",
    "satie_w_cowbell2 = satie.copy()\n",
    "for start in onsets:\n",
    "    stop = start + cowbell.shape[0]\n",
    "    satie_w_cowbell2[start:stop] += cowbell\n",
    "    \n",
    "plot_audio(satie_w_cowbell2, sr)\n",
    "Audio(satie_w_cowbell2, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's cool, but we want the cowbell to occur on every quarter note beat, not just the beats on which there is a piano note. Let's try a beat tracker instead: [`librosa.beat.beat_track`](https://librosa.github.io/librosa/generated/librosa.beat.beat_track.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The hop length of the beat tracker in samples\n",
    "hop = 128\n",
    "\n",
    "# Track the beat\n",
    "tempo, beat_frames = librosa.beat.beat_track(satie, sr, hop_length=hop, start_bpm=76, tightness=200)\n",
    "print 'Tempo: %f' % tempo\n",
    "\n",
    "# The beat tracker outputs frames. We need to convert this to samples.\n",
    "beats = librosa.frames_to_samples(beat_frames, hop_length=hop)\n",
    "\n",
    "satie_w_cowbell3 = satie.copy()\n",
    "for start in beats:\n",
    "    stop = start + cowbell.shape[0]\n",
    "    satie_w_cowbell3[start:stop] += cowbell\n",
    "    \n",
    "plot_audio(satie_w_cowbell3, sr)\n",
    "Audio(satie_w_cowbell3, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. So, it detected the tempo at half of what we expect it, but since this piece has a time signature of 3/4, the results are odd. It also decided that the onsets in the first half were not strong enough to include."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>(1 point):</b> Look at <code>librosa.beat.beat_track</code> documentation. Given what you know about the signal, adjust the arguments to the function so that it correctly outputs the onset time for each quarter note beat. Add cowbell at those beats. <b>Insert your code below and save your output to a variable named <code>satie_w_cowbell_submitted</code> and write it to a wav file named <code>satie_w_cowbell_submitted.wav</code>.</b>\n",
    "<br />\n",
    "<br />\n",
    "It should look and sound like the following:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "satie_w_cowbell_correct, sr = librosa.load('satie_w_cowbell_correct.wav', sr=sr)\n",
    "plot_audio(satie_w_cowbell_correct, sr)\n",
    "Audio(satie_w_cowbell_correct, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INSERT YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# INSERT YOUR CODE ABOVE HERE\n",
    "    \n",
    "plot_audio(satie_w_cowbell_submitted, sr)\n",
    "Audio(satie_w_cowbell_submitted, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>(1 point):</b> Using what you've learned so far, try writing code to manipulate the Satie excerpt in a new way that you find interesting (yeah... be a little creative). You can process it or add to it. Maybe try delving into <code>librosa</code> to extract information from the signal to inform the way you process it. Below is an example to give you more ideas. Make your own though... working with audio is fun! Ohh, and please comment your code, stating what your intention is with each step.\n",
    "<br />\n",
    "<br />\n",
    "<b>Save your output signal to a variable named <code>that_crazy_old_satie</code> and write it to a wav file named <code>that_crazy_old_satie.wav</code>.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# copy satie\n",
    "satie_bkwds = satie.copy()\n",
    "\n",
    "# add in a pitched up cowbell at 77 * 4 bpm\n",
    "beats = np.round(np.arange(0,30,60 / (77*4.0)) * sr).astype('int')\n",
    "\n",
    "for start in beats:\n",
    "    stop = start + cowbell[::2].shape[0]\n",
    "    satie_bkwds[start:stop] += (cowbell[::2] * 0.1)\n",
    "\n",
    "\n",
    "# let's double the speed and reverse it too\n",
    "satie_bkwds = satie_bkwds[::-2]\n",
    "    \n",
    "# find 2 strongest chroma in the satie\n",
    "chroma_cq = librosa.feature.chroma_cqt(satie, sr=sr)\n",
    "idx1 = np.argsort(np.mean(chroma_cq, axis=1))[-1]\n",
    "idx2 = np.argsort(np.mean(chroma_cq, axis=1))[-2]\n",
    "\n",
    "# calculate the frequencies\n",
    "freq1 = 261.6 * (2 ** (idx1 / 12.)) * 0.5\n",
    "freq2 = 261.6 * (2 ** (idx2 / 12.)) * 0.5\n",
    "\n",
    "# synthesize a drone\n",
    "length = float(satie_bkwds.shape[0]) / sr\n",
    "t = np.linspace(0,length,satie_bkwds.shape[0])\n",
    "bass = np.sin(2*np.pi*freq1*t) + np.sin(2*np.pi*freq2*t) + np.sin(2*np.pi*freq2*0.5*t)\n",
    "\n",
    "# modulate\n",
    "mod_sig = (1 + np.sin(2*np.pi*0.1*t)) + 0.5\n",
    "mod_sig2 = (1 + np.sin(2*np.pi*mod_sig*t))\n",
    "bass = bass * (0.5 * mod_sig2)\n",
    "\n",
    "# distort\n",
    "bass = distort(bass)\n",
    "    \n",
    "that_crazy_old_satie = (bass * 0.5) + satie_bkwds\n",
    "that_crazy_old_satie = that_crazy_old_satie / np.max(np.abs(that_crazy_old_satie))\n",
    "\n",
    "plot_audio(that_crazy_old_satie, sr)\n",
    "Audio(that_crazy_old_satie, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INSERT YOUR CODE BELOW\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# INSERT YOUR CODE ABOVE\n",
    "\n",
    "plot_audio(that_crazy_old_satie, sr)\n",
    "wavwrite('that_crazy_old_satie.wav', that_crazy_old_satie, sr)\n",
    "Audio(that_crazy_old_satie, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Rerun your code and double-check the output\n",
    "Now, to make sure you haven't accidentally removed code necessary to generate the output you expect:\n",
    "1. Clear all output and restart the Jupyter Python kernel\n",
    "    1. Select the \"Kernel\" drop-down menu\n",
    "    1. Click \"restart\"\n",
    "    1. Select \"Clear all outputs & restart\"\n",
    "1. Run all cells\n",
    "    1. Select the \"Cell\" drop-down menu\n",
    "    1. click \"Run All\"\n",
    "1. Check that your output (figures, audio, numbers, etc.) is as you expect\n",
    "1. If the output is correct, you're done. If the output is not correct, debug and repeat until the output is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's all for this week!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
